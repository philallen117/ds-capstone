---
title: "Corpus data exploration"
author: "Phil Allen"
date: "1 May 2016"
output: html_document
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
# publish to http://rpubs.com/philallen117/ds-capstone-explore
knitr::opts_chunk$set(echo=FALSE)
knitr::opts_chunk$set(fig.keep=TRUE)
knitr::opts_chunk$set(warning=FALSE)
library(parallel)
options(mc.cores = 4)
library(wordcloud)
library(sm)
library(quanteda)
library(scales)
library(ggplot2)
```
```{r aesdefs, cache=TRUE}
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", 
                "#0072B2", "#D55E00", "#CC79A7")
reverselog_trans <- function(base = exp(1)) {
  trans <- function(x) -log(x, base)
  inv <- function(x) base^(-x)
  trans_new(paste0("reverselog-", format(base)), trans, inv, 
            log_breaks(base = base), 
            domain = c(1e-100, Inf))
}
```
```{r pp, cache=TRUE, cache.lazy=FALSE}
load("data/pp.8.RData")
```

# Objectives and approach

The objectives up to this point have been.

* Establish appropriate pre-processing of the corpora.
* Analyze frequencies of words and n-grams.
* Compare the corpora on frequencies, and most frequent terms.

I have used density plots rather than histograms, and a colour-blind-friendly palette. These choices make comparison of corpora easier for me, and I hope they do not offend the markers.

The results are for the en-US corpora, only. I analyzed words, bigrams, and trigrams. Words and trigrams were the more interesting, and I present them below

# Data source

The data have been contributed by Swiftkey. There are three corpora: blogs, news, tweets. They were collected over an unknown time period and unknown number of users; all we are given is the documents themselves. Later in the project, having corpora from different online media will help us to test the robustness of our prediction approaches for different kinds of writing.

# Processing

The data reads successfully as UTF-8. Since the target application is text prediction on mobile devices, in English, I decided to transliterate to ASCII. I also removed punctuation including quoting, and digits, since none of these are high priorities targets for text prediction. (There could be valuable special cases, such as "2016", but I will deal with those later.) Ellided words such as "don't" are preserved.

I applied the same pre-processing to all corpora for purposes of comparison. When we move to prediction, that probably won't work for tweets because of tags and IDs. Tags could benefit from the use of a dictionary to separate word boundaries, e.g #tellitlikeitis. IDs are less regular (in the quest to avoid clashes). The user could be supported by look-up of past choices.

# Gross structural features of the corpora

```{r lens, dependson='pp', cache=TRUE}
lens <- function(c, v, d) data.frame(corpus=c, lenChars=nchar(v), lenWords=rowSums(d))
lensdf <- rbind(lens("twitter", v[["twitter"]], dfm1[["twitter"]]),
                lens("blogs", v[["blogs"]], dfm1[["blogs"]]),
                lens("news", v[["news"]], dfm1[["news"]]))
```

First examine the distribtion of lengths of documents in the three corpora, in terms of characters.

```{r lenChars, dependson=c('lens', 'aesdefs'), fig.height=3}
ggplot(lensdf, aes(x=lenChars, colour=corpus)) +
  geom_density() + 
  scale_x_log10() +
  scale_colour_manual(values=cbbPalette) +
  xlab("Document length (characters)") + 
  ggtitle("Density of document length (chars)")
```

The lengths of tweets cluster towards their technical limit, while the other media are much longer.

```{r lenWordss, dependson=c('lens', 'aesdefs'), fig.height=3}
ggplot(lensdf, aes(x=lenWords, colour=corpus)) +
  geom_density() + 
  scale_x_log10() +
  scale_colour_manual(values=cbbPalette) +
  xlab("Document length (words)") + 
  ggtitle("Density of document length (words)")
```

Lengths of news items cluster more about their node than do blog posts. News writers are often working to house guidelines, while blog writers may not be under such constraints.

# Feature frequency

```{r freqs, dependson='pp', cache=TRUE}
totalWordOccurrences <- lapply(lapply(dfm1, colSums), sum)
totalGram3Occurrences <- lapply(lapply(dfm3, colSums), sum)
feat <- function(c, d, tot) {
  freqt <- 1 + colSums(d)
  data.frame(corpus=c,
             feature=features(d), 
             freq=freqt, 
             normFreq=freqt/tot)
}
feat1df <- rbind(feat("twitter", dfm1[["twitter"]], totalWordOccurrences[["twitter"]]),
                 feat("blogs", dfm1[["blogs"]], totalWordOccurrences[["blogs"]]),
                 feat("news", dfm1[["news"]], totalWordOccurrences[["news"]]))
feat3df <- rbind(feat("twitter", dfm1[["twitter"]], totalGram3Occurrences[["twitter"]]),
                 feat("blogs", dfm1[["blogs"]], totalGram3Occurrences[["blogs"]]),
                 feat("news", dfm1[["news"]], totalGram3Occurrences[["news"]]))
```

## Distribution of single words

The following plot shows the density of word frequencies within the corpora. The x-axis is log10, and reversed so that it runs from most to least frequent.

```{r wordsfreqabs, dependson=c('freqs', 'aesdefs'), fig.height=3}
ggplot(feat1df, aes(x=freq, group=corpus, colour=corpus)) +
  geom_density() + 
  scale_x_continuous(trans=reverselog_trans(10)) +
  # scale_x_log10(limits=c(1,1000)) +
  scale_colour_manual(values=cbbPalette) +
  xlab("Frequency of word") + 
  ggtitle("Density of word frequency by corpus")
```

However, the corpora are different sizes. Here is the same plot normalized by
the total word occurrences in the respective corpora, again with x-axis log10 and reversed.

```{r wordsfreqnorm, dependson=c('freqs', 'aesdefs'), fig.height=3}
ggplot(feat1df, aes(x=normFreq, group=corpus, colour=corpus)) +
  geom_density() + 
  scale_x_continuous(trans=reverselog_trans(10)) +
  # scale_x_log10() +
  scale_colour_manual(values=cbbPalette) +
  xlab("Normalized frequency of word") + 
  ggtitle("Density of normalized word frequency by corpus")
```

In all corpora, most words are used relatively infrequently. But the news peak shows at a higher relative frequency for news than for blogs and tweets. This suggests that news has a more constrained vocabulary.

## Most frequent single words

Here are the 12 most frequent words in each of the corpora.

```{r top.word, dependson='pp', results='asis'}
knitr::kable(as.data.frame(lapply(lapply(dfm1, topfeatures, 12), names)))
```

As noted above, I have not removed stop words. So we see a great deal of common articles, preposions, connectives. In comparison with news, blogs introduce first person pronouns. Tweets also use second person pronouns; though are broadcast, they are often addressed to one person. This impression can also be illustrated with wordclouds (top 100).

```{r wordclouds, dependson='pp'}
old.par <- par(mfrow = c(1, 3))
wc <- function(d1, t) {
  wf <- sort(colSums(d1), decreasing=TRUE)
  wordcloud(names(wf), wf, max.words=100) # 100 takes a while
  title(t)
}
wc(dfm1[["twitter"]], "Cloud for twitter")
wc(dfm1[["blogs"]], "Cloud for blogs")
wc(dfm1[["news"]], "Cloud for news")
par(old.par)
```

## Distribution of trigrams

This plot shows the density of trigram frequencies by corpus, normalized by total occurrences for each corpus, with the x-axis log10 and reversed, as for single words, above.

```{r trigramfreqnorm, dependson=c('freqs', 'aesdefs'), fig.height=3}
ggplot(feat3df, aes(x=normFreq, group=corpus, colour=corpus)) +
  geom_density() + 
  scale_x_continuous(trans=reverselog_trans(10)) +
  # scale_x_log10() +
  scale_colour_manual(values=cbbPalette) +
  xlab("Frequency of trigram") + 
  ggtitle("Density of trigram frequency by corpus")
```

As for single words, most trigrams are infrequent, but this peak occurs at greater frequency for news items, suggesting a more constrained vocabulary.

## Most frequent trigrams

```{r top.gram3, dependson='pp', results='asis'}
knitr::kable(as.data.frame(lapply(lapply(dfm3, topfeatures, 15), names)))
```

In all three corpora, we can see short sequences denoting common relationships between words or phrases, such as "a lot of", "be able to". News introduces reported speech ("according to the"). The only personal pronoun is found in "you have to". We may suspect this to be in the sense of "one has to". In blogs, we find first person phrases ("i have been", i had to"). As with single words, we find that tweets are frequently personally addressed: writers thank people, and say "i love you". They also refer to plans, e.g. "I want to", "going to be".

## Conclusion

Even with simple techniques, we can tell a lot about use of English in the corpora, including the different ways that people use these three different media.

* News is the most uniform of three corpora in length and vocabulary use, and is not in the first person. Its vocabulary is the most constrained of the corpora.
* Blogs are more varied than news. They are in the first person, and may talk about attitudes or plans, suggesting a journal style of writing.
* Tweets are decidedly first person, and very often addressed to a second person. They often express thanks or love.
